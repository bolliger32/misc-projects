{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Car Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import describe\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(X_fname,Y_fname, drop_mask=True, add_preview_data=True,\n",
    "              preview_data='test_locations_and_labels_preview.np',\n",
    "              preview_im = 'parking_test_preview.png'):\n",
    "    X = np.load(X_fname)\n",
    "    Y = np.load(Y_fname)\n",
    "    \n",
    "    # remove observation with missing data due to being too close to the edge of the image.\n",
    "    ix_0 = []\n",
    "    for i,j in enumerate(X):\n",
    "        if j.shape[0] < 1600:\n",
    "            ix_0.append(i)\n",
    "    ix_0\n",
    "\n",
    "    mask = np.ones(len(X),dtype=bool)\n",
    "    mask[ix_0]=False\n",
    "    X, Y = X[mask], Y[mask]\n",
    "    \n",
    "    # return 2D array rather than array of arrays\n",
    "    X = np.vstack(X)\n",
    "    \n",
    "    # add on PREVIEW TEST DATA (if we have access to it, why not??)\n",
    "    if add_preview_data:\n",
    "        X,Y = add_data(X,Y,preview_data,preview_im)\n",
    "    \n",
    "    # drop transparency mask values\n",
    "    num_ftrs = X.shape[1]\n",
    "    mask = np.ones(num_ftrs,dtype=bool)\n",
    "    trans_ix = range(3,num_ftrs,4)\n",
    "    mask[trans_ix]=False\n",
    "    X = X[:,mask]\n",
    "    \n",
    "    return X,Y\n",
    "    \n",
    "def add_data(X,Y,preview_data,preview_im):\n",
    "    im = plt.imread(preview_im)\n",
    "    test_locs_labs = np.load('test_locations_and_labels_preview.np')\n",
    "    test_locs   = test_locs_labs[:,0:2]\n",
    "    Y_test = test_locs_labs[:,2]\n",
    "    \n",
    "    X_test = []\n",
    "    for loc in test_locs:\n",
    "        X_test.append( my_feature_vector(loc, im) )\n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    X_result = np.vstack((X,X_test))\n",
    "    Y_result = np.hstack((Y,Y_test))\n",
    "    return X_result, Y_result\n",
    "    \n",
    "def my_feature_vector(loc, im, size = 10):\n",
    "    w = size\n",
    "    # a patch of the size w cenetered at loc is extracted as a feature vector\n",
    "    patch = im[loc[1]-w:loc[1]+w, loc[0]-w:loc[0]+w]\n",
    "    p = np.array(patch).flatten()\n",
    "    return p \n",
    "\n",
    "def scorer(estimator,X,y):\n",
    "    score = 0\n",
    "    y_pred = estimator.predict(X)\n",
    "    score_arr = 2 * ((y_pred == 1.) & (y == 1.)) + .25 * ((y_pred == 0.) & (y == 0.)) - .5 * (y_pred != y)\n",
    "    \n",
    "    # weight such that there are equal cars and non-cars in sample (like in test dataset)\n",
    "    total_cars = float((y==1.).sum())\n",
    "    total_noncars = float((y==0.).sum())\n",
    "    multiplier = ((y==1.) / total_cars + (y==0.) / total_noncars)\n",
    "    score_arr = score_arr*multiplier\n",
    "    \n",
    "    score = score_arr.sum()\n",
    "    return score\n",
    "\n",
    "def get_new_search_limits(grid,selected_param):\n",
    "    \"\"\"Returns the adjacent grid elements to the optimal parameter from a grid search\"\"\"\n",
    "    ix = np.nonzero(grid == selected_param)[0][0]\n",
    "    if ix == 0:\n",
    "        raise IndexError(\"ERROR: Best parameter is at edge of search grid. Adjust search grid and re-run.\")\n",
    "    return grid[ix-1],grid[ix+1]\n",
    "\n",
    "def still_above_threshold(diff_dict,th_dict):\n",
    "    assert len(diff_dict) == len(th_dict)\n",
    "    for i in diff_dict.keys():\n",
    "        if diff_dict[i] >= th_dict[i]:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/ipykernel/__main__.py:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "X,Y = load_data('X_trn.np','Y_trn.np')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVC classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial, broad grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_length=9\n",
    "n_folds = 3\n",
    "np.random.seed(0)\n",
    "\n",
    "search_params = {}\n",
    "search_params['C'] = np.logspace(-3,5,grid_length)\n",
    "search_params['gamma'] = np.logspace(-5,0,grid_length)\n",
    "# search_params['degree'] = [4,5,6]\n",
    "search_params['coef0'] = np.array((-1,-.5,0,.5,1))\n",
    "# not sure which is better, sample-frequency-weighting OR weighting by \"opportunity cost\" of\n",
    "# missing each class (3.33 times greater for misclassifying car (2.5 pt hit) vs. misclassifying\n",
    "# non-car (.75 pt hit)) OR the product of the two weights\n",
    "total_cars = float((Y==1.).sum())\n",
    "total_noncars = float((Y==0.).sum())\n",
    "opp_cost = {1.:10/3}\n",
    "opp_cost_X_freq_weight = {1.:(10/3) * total_noncars / total_cars}\n",
    "\n",
    "# I THINK that the opp_cost_X_freq_weight weighting will be optimal,\n",
    "# and I am searching across a wide array of params, so I'll leave \n",
    "# this set for now. If time, I will try all 3.\n",
    "search_params['class_weight'] = [opp_cost_X_freq_weight]\n",
    "# search_params['class_weight'] = ['auto',opp_cost,opp_cost_X_freq_weight]\n",
    "\n",
    "# using limited grid search for polynomial kernel b/c of time expense\n",
    "# these parameters were arrived at via separate poly-only, manual grid search\n",
    "search_grid = [{'kernel':['linear'],  'C':search_params['C'], 'class_weight': search_params['class_weight']},\n",
    "               {'kernel':['rbf'],     'C':search_params['C'], 'class_weight': search_params['class_weight'],\n",
    "                    'gamma':search_params['gamma']},\n",
    "               {'kernel':['poly'],    'C':[.01,.1,1], 'class_weight': search_params['class_weight'],\n",
    "                    'gamma':[.001,.01,.1], 'coef0':[.5,1,1.5], 'degree':[2,3]},\n",
    "               {'kernel':['sigmoid'], 'C':search_params['C'], 'class_weight': search_params['class_weight'],\n",
    "                    'gamma':search_params['gamma'], 'coef0':search_params['coef0']}]\n",
    "               \n",
    "# {'kernel':['poly'],    'C':search_params['C'], 'class_weight': search_params['class_weight'],\n",
    "#                     'gamma':search_params['gamma'], 'coef0':search_params['coef0'], 'degree':search_params['degree']}\n",
    "\n",
    "score_func = make_scorer(scorer)\n",
    "n = X.shape[0]\n",
    "# use stratified k-fold so that hard-coded frequency weights make sense (opp_cost_X_freq_weight)\n",
    "cross_val = StratifiedKFold(Y, n_folds, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this cell when comparing across all kernels\n",
    "pred = GridSearchCV(SVC(random_state = seed),\n",
    "                    param_grid = search_grid,\n",
    "                    cv = cross_val, n_jobs = -1, scoring = scorer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run these cells only for testing to make sure that the search grid is appropriately wide for each kernel type\n",
    "pred = GridSearchCV(SVC(random_state = seed, kernel = 'sigmoid', class_weight = opp_cost_X_freq_weight),\n",
    "                    param_grid = {'C':search_params['C'],\n",
    "                                  'gamma':search_params['gamma'],\n",
    "                                  'coef0':search_params['coef0']},\n",
    "                    n_jobs = -1, scoring = scorer, cv = cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run these cells only for testing to make sure that the search grid is appropriately wide for each kernel type\n",
    "pred = GridSearchCV(SVC(random_state = seed, kernel = 'linear', class_weight = opp_cost_X_freq_weight),\n",
    "                    param_grid = {'C':search_params['C']},\n",
    "                    n_jobs = -1, scoring = scorer, cv = cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run these cells only for testing to make sure that the search grid is appropriately wide for each kernel type\n",
    "pred = GridSearchCV(SVC(random_state = seed, kernel = 'poly', class_weight = opp_cost_X_freq_weight),\n",
    "                    param_grid = {'C':[.01,.1,1],\n",
    "                                  'gamma':[.001,.01,.1],\n",
    "                                  'coef0':[.5,1,1.5],\n",
    "                                  'degree':[2,3]},\n",
    "                    n_jobs = -1, scoring = scorer, cv = cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.056234132519034911, 'class_weight': {1.0: 6.7682926829268295}}\n",
      "2.01270050538\n"
     ]
    }
   ],
   "source": [
    "pred.fit(X,Y)\n",
    "best_params = pred.best_params_\n",
    "best_score = pred.best_score_\n",
    "\n",
    "print best_params\n",
    "print best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save this initial guess at a classifier\n",
    "with open('classifier_0.pickle','wb') as f:\n",
    "pickle.dump(pred.best_estimator_,f)\n",
    "\n",
    "# pickle best_params, best_score, search_grid too\n",
    "with open('first_search_params.pickle','wb') as f:\n",
    "    pickle.dump((best_params,best_score,search_grid),f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, choose best kernel type and parameter order of magnitude, and do finer-grained grid searches until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load search params\n",
    "with open('first_search_params.pickle','rb') as f:\n",
    "    best_params,best_score,search_grid = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = best_params['kernel']\n",
    "class_weight = best_params['class_weight']\n",
    "\n",
    "fixed_params = {}\n",
    "fixed_params['kernel'] = kernel\n",
    "fixed_params['class_weight'] = class_weight\n",
    "if fixed_params['kernel'] == 'poly':\n",
    "    degree = best_params['degree']\n",
    "    fixed_params['degree'] = degree\n",
    "    \n",
    "# drop the fixed params from \"best_params\"\n",
    "for i in fixed_params.keys():\n",
    "    del best_params[i]\n",
    "\n",
    "# choose starting parameters\n",
    "if kernel == 'linear': grid_ix=0\n",
    "elif kernel == 'rbf' : grid_ix=1\n",
    "elif kernel == 'poly': grid_ix=2\n",
    "elif kernel == 'sigmoid': grid_ix=3\n",
    "    \n",
    "search_grid = search_grid[grid_ix]\n",
    "\n",
    "# set thresholds\n",
    "th_all = {}\n",
    "for i in best_params.keys():\n",
    "    th_all[i] = abs(best_params[i]/10.)\n",
    "th_score = abs(best_score / 1000.)\n",
    "# create difference dict\n",
    "diff = th_all.copy()\n",
    "diff_score = th_score\n",
    "\n",
    "# create new cv object w/ more folds\n",
    "n_folds_2 = 10\n",
    "cross_val_2 = StratifiedKFold(Y, n_folds_2, shuffle=True, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #: 1\n",
      "search grid: {'C': array([ 0.01   ,  0.13375,  0.2575 ,  0.38125,  0.505  ,  0.62875,\n",
      "        0.7525 ,  0.87625,  1.     ]), 'gamma': array([ 0.01333521,  0.04131048,  0.06928575,  0.09726102,  0.12523629,\n",
      "        0.15321156,  0.18118683,  0.2091621 ,  0.23713737])}\n",
      "best params: {'C': 0.38124999999999998, 'gamma': 0.097261022913332856}\n",
      "best score: 2.047905351\n",
      "iteration #: 2\n",
      "search grid: {'C': array([ 0.2575   ,  0.2884375,  0.319375 ,  0.3503125,  0.38125  ,\n",
      "        0.4121875,  0.443125 ,  0.4740625,  0.505    ]), 'gamma': array([ 0.06928575,  0.07627957,  0.08327339,  0.09026721,  0.09726102,\n",
      "        0.10425484,  0.11124866,  0.11824248,  0.12523629])}\n",
      "best params: {'C': 0.4740625, 'gamma': 0.11124865767861612}\n",
      "best score: 2.04925968486\n"
     ]
    }
   ],
   "source": [
    "# iterate linear grid search with finer mesh until the change in best values is under a threshold\n",
    "iterations = 1\n",
    "while (still_above_threshold(diff,th_all)) and (diff_score >= th_score):\n",
    "    print \"iteration #:\", iterations\n",
    "    \n",
    "    search_grid_old = search_grid.copy()\n",
    "    search_grid = {}\n",
    "\n",
    "    for i in best_params.keys():\n",
    "        lims = get_new_search_limits(search_grid_old[i],best_params[i])\n",
    "        search_grid[i] = np.linspace(lims[0],lims[1],grid_length)\n",
    "            \n",
    "    print \"search grid:\", search_grid\n",
    "\n",
    "\n",
    "    if kernel == 'poly':\n",
    "        clf = SVC(random_state=seed, kernel=kernel, class_weight=class_weight, degree = degree)\n",
    "    else:\n",
    "        clf = SVC(random_state=seed, kernel=kernel, class_weight=class_weight)\n",
    "        \n",
    "    pred = GridSearchCV(clf, param_grid=search_grid, cv=cross_val_2, n_jobs=-1, scoring=scorer)\n",
    "\n",
    "    pred.fit(X,Y)\n",
    "    best_params_old = best_params.copy()\n",
    "    best_score_old = best_score.copy()\n",
    "    best_params = pred.best_params_\n",
    "    best_score = pred.best_score_\n",
    "    for i in best_params.keys():\n",
    "        diff[i] = abs(best_params[i]-best_params_old[i])\n",
    "    diff_score = abs(best_score - best_score_old)\n",
    "    \n",
    "    iterations += 1\n",
    "\n",
    "    print \"best params:\", best_params\n",
    "    print \"best score:\", best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save final classifier\n",
    "with open('classifier.pickle','wb') as f:\n",
    "    pickle.dump(pred.best_estimator_,f)\n",
    "\n",
    "# pickle best_params, best_score, search_grid too\n",
    "with open('final_search_params.pickle','wb') as f:\n",
    "    pickle.dump((best_params,best_score,search_grid),f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
